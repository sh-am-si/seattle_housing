{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import utils \n",
    "import my_transformers\n",
    "import const\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "\n",
    "df = utils.PrepareData().df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(my_transformers)\n",
    "from my_transformers import DropColumns, YearTransformer, ColumnToDateFormat, Drop33Rooms\n",
    "\n",
    "transform_pipeline = Pipeline([\n",
    "        ('yr_built_transformer', YearTransformer(column='yr_built')),\n",
    "        ('33_bedrooms_row_drop', Drop33Rooms()),\n",
    "        ('clean_flaw', DropColumns(columns=['id', 'date', 'yr_renovated'])),\n",
    "        # ('clean_flaw', DropColumns(columns=['bathrooms'])),\n",
    "        # ('clean_geodata', DropColumns(columns=['zipcode', 'lat', 'long'])),\n",
    "        ('clean_duplicate', DropColumns(columns=['price'])),\n",
    "     ])\n",
    "ndf = transform_pipeline.transform(df)\n",
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logical Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['price_bin'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "sdf = utils.get_equal_samples(ndf, column='price_bin', mult_coef=1)\n",
    "sdf['price_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(5, 5))\n",
    "sdf['waterfront'].hist(ax=ax)\n",
    "sdf[sdf['price_bin']==1]['waterfront'].hist(ax=ax)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(5, 5))\n",
    "sdf['view'].hist(ax=ax, label='all sales')\n",
    "sdf[sdf['price_bin']==1]['view'].hist(ax=ax, label='over 1 ml')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(5, 5))\n",
    "sdf['condition'].hist(ax=ax, label='all sales')\n",
    "sdf[sdf['price_bin']==1]['condition'].hist(ax=ax, label='over 1 ml')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(ndf[['floors', 'grade', 'bedrooms', 'condition', 'view', 'price_bin']], hue='price_bin', corner=True, size=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(ndf[['floors', 'grade', 'bedrooms', 'condition', 'view', 'price_bin']], hue='price_bin', corner=True, size=5);sns.pairplot(ndf[['floors', 'grade', 'bedrooms', 'condition', 'view', 'price_bin']], hue='price_bin', corner=True, size=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdf = ndf.copy()\n",
    "train_X, test_X, train_y, test_y = train_test_split(\n",
    "    sdf.drop(columns=['price_bin'], inplace=False), \n",
    "    sdf['price_bin'],\n",
    "    test_size=const.TEST_SIZE,\n",
    "    random_state=const.RANDOM_STATE\n",
    "    )\n",
    "\n",
    "' - '.join([str(getattr(v, 'shape')) for v in (train_X, test_X, train_y, test_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier(random_state=const.RANDOM_STATE)\n",
    "sgd.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(sgd, train_X, train_y, cv=5, scoring='accuracy')\n",
    "# sgd.predict(test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = cross_val_predict(sgd, train_X, train_y, cv=5)\n",
    "precision, recall , threshold = precision_recall_curve(train_y, train_y_pred)\n",
    "\n",
    "plt.plot(threshold, precision[:-1], 'b', label='precision')\n",
    "plt.plot(threshold, recall[:-1], 'g', label='recall')\n",
    "plt.xlabel('threshold')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression(multi_class='multinomial',\n",
    "#                         solver='lbfgs',\n",
    "#                         C=8)\n",
    "lr = LogisticRegression(multi_class='multinomial',\n",
    "                        solver='lbfgs',\n",
    "                        C=8)\n",
    "lr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_pred = cross_val_predict(lr, train_X, train_y, cv=2)\n",
    "confusion_matrix(train_y, train_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred = lr.predict(test_X)\n",
    "confusion_matrix(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'multi_class': ['auto', 'ovr', 'multinomial' ],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C': [3, 5, 8, 10, 12]\n",
    "    }\n",
    "grid = GridSearchCV(estimator=lr,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='r2',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)\n",
    "                    \n",
    "grid_result = grid.fit(train_X, train_y)\n",
    "\n",
    "print('Best Score: ', grid_result.best_score_)\n",
    "print('Best Params: ', grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics, svm\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=2, weights='uniform')\n",
    "knn.fit(train_X, train_y)\n",
    "predict = knn.predict(test_X)\n",
    "accuracy = metrics.accuracy_score(test_y, predict)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(test_y, predict)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_svm = svm.SVC()\n",
    "_svm.fit(train_X, train_y)\n",
    "prediction = _svm.predict(test_X)\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_y, prediction)\n",
    "print(\"predictions:\", prediction)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(test_y, predict)\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA(n_components=2)            \n",
    "model.fit(train_X)                  \n",
    "X_2D = model.transform(ndf.drop(columns=['price_bin'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = ndf.copy()\n",
    "df_pca['PCA1'] = X_2D[:, 0]\n",
    "df_pca['PCA2'] = X_2D[:, 1]\n",
    "sns.lmplot(\"PCA1\", \"PCA2\", hue='price_bin', data=df_pca, fit_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PCA(n_components=3)            \n",
    "model.fit(train_X)                  \n",
    "X_3D = model.transform(ndf.drop(columns=['price_bin'])) \n",
    "df_pca['PCA_1'] = X_3D[:, 0]\n",
    "df_pca['PCA_2'] = X_3D[:, 1]\n",
    "df_pca['PCA_3'] = X_3D[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(df_pca['PCA_1'], df_pca['PCA_2'], df_pca['PCA_3'], c=df_pca['price_bin'], marker='o', cmap='jet')\n",
    "ax.set_xlabel('PCA1 Label')\n",
    "ax.set_ylabel('PCA2 Label')\n",
    "ax.set_zlabel('PCA3 Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('houses-env': venv)",
   "name": "python37564bithousesenvvenv81d0e4f1e66c470d9a85d728409cf3f3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
